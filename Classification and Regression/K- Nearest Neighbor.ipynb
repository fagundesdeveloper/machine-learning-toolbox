{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbor is an algorithim for classification. Given some plotted data KNN attempts to classify new points by looking at the class of nearby data points. \n",
    "\n",
    "### Properties \n",
    "1. Very simple, training is trivial, works with many classes, it's easy to add more data, and there are few paramerters(k and distance metric)\n",
    "\n",
    "### Limitations\n",
    "1. High prediciton cost- it's worse for large data sets where you are having to sort what points are closest to the new data point- this is exacerbated by high dimensional data\n",
    "2. Categorical features don't work well\n",
    "\n",
    "### Psuedo Code\n",
    "1. Calculate the distance from X to all points in your data.\n",
    "2. Sort the points in your data by increasing distance from X\n",
    "3. Predict the majority label of the 'k' closest points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-cdead3f0742b>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-cdead3f0742b>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    from sklearn.cross_validation import train_test_split()\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('Classified Data', index_col=0)\n",
    "\n",
    "# scale has a large effect on observations when computing distance\n",
    "# we must scale the data first\n",
    "\n",
    "#scale using the sklearn standard scaler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fir(df.drop('TARGET CLASS', axis = 1))\n",
    "StandardScaler(copy=True, with_mea=True, with_std=True)\n",
    "scaled_features = scaler.transform(df.drop('TARGET CLASS', axis=1))\n",
    "\n",
    "df_feat= pd.DataFrame(scaled_features, columns = df.columns[:-1])\n",
    "\n",
    "from sklearn.cross_validation import train_test_split()\n",
    "#use tab shift, scroll down and find the example to save time\n",
    "#set test size to some decimal \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn= kNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "pred = knn.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import classifcation_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "error_rate = []\n",
    "\n",
    "\n",
    "# we want to plot the error rate and run the classifer with\n",
    "# a variety of k values- we can use the elbow method to figure out\n",
    "#which vlaue is best \n",
    "\n",
    "for i in range(1, 40):\n",
    "    knn = kNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred_i = knn.predict(x_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 40), error_rate, color = 'blue', ls='dashed', marker='o',\n",
    "        markercolor='red', markersize=10)\n",
    "plt.title('error rate vs k vlaue')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('error rate')\n",
    "\n",
    "#in this case the graph is fairly bumpy- this is because the\n",
    "# error rate is already pretty low. \n",
    "\n",
    "knn = kNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(x_train, y_train)\n",
    "pred_i = knn.predict(x_test)\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
