{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A perceptron is a very simple surpervised learning algorithm of binary classification. It was the first artificial neural network produced. \n",
    "\n",
    "A single layer perceptron is only capable of learning linearly seperable patterns, but a multilayer perceptron with 2-3 or more layers, also called a feedforward neural network, can. \n",
    "\n",
    "## Properties \n",
    "\n",
    "\n",
    "## Limitations\n",
    "\n",
    "\n",
    "## Psuedo Code\n",
    "1. Each layer has a bias and a parameter, \n",
    "2. We pass the data to the first layer, we multiply the data by the weights and then the biases\n",
    "3. We then multiply it by the activation function, RELU, and pass it to the next layer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = mnist.train.images[2023].reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1b275a6898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b275e2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know what our data looks like, lets set some parameters: the learning rate, the number of training epochs, and the batch size. Then we set parameters for network architeture: n_classes, n_sample, n_input of data set, n_hidden layer size. Lastly we will use an output layer with softmax with cross entropy and the built-in adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#network architecture parameters\n",
    "n_classes = 10\n",
    "n_sample = mnist.train.num_examples\n",
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Place Holder for Data Input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dicitionary of biases\n",
    "    '''\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create two dictionaries with out weights and our bias objects for the model. Then we will introduce a new object type from tensor flow called tf.variable- this is a little different than a constant, tf has whats called a gaph object that can become aware of the states of all the variables- and a variable is a modifiable tensor that lives in tensorflow's graph of interacting operations and it can be used and modified by the computation. We will generally have the model parameters be variables. A tf.variable maintains state in the graph across all the calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    # a matrix of normally distributed random values\n",
    "    # with n_input rows and n_hidden_1 columns\n",
    "    'h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "tf.nn.softmax_cross_entropy_with_logits\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Running the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch of the MNIST data. It will return a tuple with the x and y values, which we can then unpack with tuple unpacking. We can then take the array of xsamp and reshape it and then plot it. \n",
    "\n",
    "When we run the model instead of using 'with tf.session() as sess:' we are going to launch an interactive session with sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = mnist.train.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffa243cc1d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa244418d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsamp, ysamp = t\n",
    "plt.imshow(xsamp.reshape(28, 28), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Cost: 0.2291\n",
      "Epoch: 2 Cost: 0.2446\n",
      "Epoch: 3 Cost: 0.1699\n",
      "Epoch: 4 Cost: 0.1732\n",
      "Epoch: 5 Cost: 0.2037\n",
      "Epoch: 6 Cost: 0.2429\n",
      "Epoch: 7 Cost: 0.2142\n",
      "Epoch: 8 Cost: 0.1716\n",
      "Epoch: 9 Cost: 0.1249\n",
      "Epoch: 10 Cost: 0.1742\n",
      "Epoch: 11 Cost: 0.1542\n",
      "Epoch: 12 Cost: 0.1819\n",
      "Epoch: 13 Cost: 0.1774\n",
      "Epoch: 14 Cost: 0.1913\n",
      "Epoch: 15 Cost: 0.1974\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    # average cost\n",
    "    avg_cost = 0.0\n",
    "    total_batch = int(n_sample/batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # we won't use the _\n",
    "        _,c = sess.run([optimizer, cost], feed_dict={x:batch_x, y:batch_y})\n",
    "        \n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch: {} Cost: {:.4f}\".format(epoch+1, avg_cost))\n",
    "    \n",
    "print(\"Model has completed {} Epochs of training\".format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions = tf.cast(correct_predictions, 'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = tf.reduce_mean(correct_predictions)\n",
    "#mnist.test.lables[0]\n",
    "accuracy.eval({x: mnist.test.images, y:mnist.test.labels})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
