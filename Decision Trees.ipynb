{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees involve the greedy selection of the best split point from the dataset at each step. This algorithim makes decision trees susceptible to high variance if they are not pruned. One way around this is to  create multiple trees with different samples of the training dataset and combining predictions, this is called bootsrap aggregation or bagging. However if trees have similar split points then it mitigates the variance that was sought and predictions are likely to be similar. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
